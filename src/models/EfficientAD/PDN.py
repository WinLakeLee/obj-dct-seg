import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import numpy as np
import os
import logging
import timm

from src.utils.data_utils import build_torch_transform, make_torch_dataloader


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("EfficientAD")


# ==========================================
# 1. ëª¨ë¸ ì•„í‚¤í…ì²˜ (PDN - Patch Description Network)
# ==========================================
class PDN(nn.Module):
    """
    ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ ê²½ëŸ‰í™”ëœ íŠ¹ì§• ì¶”ì¶œ ë„¤íŠ¸ì›Œí¬ (Small ë²„ì „)
    ImageNet ì‚¬ì „ í•™ìŠµì˜ íš¨ê³¼ë¥¼ ë‚´ë©´ì„œë„ í›¨ì”¬ ë¹ ë¦„.
    """

    def __init__(self, out_channels=384):
        super(PDN, self).__init__()
        # EfficientADëŠ” 4x4 Convì™€ AvgPoolì„ ì ê·¹ ì‚¬ìš©í•˜ì—¬ Aliasingì„ ë°©ì§€í•¨
        self.conv1 = nn.Conv2d(3, 128, kernel_size=4, stride=1, padding=3)
        self.conv2 = nn.Conv2d(128, 256, kernel_size=4, stride=1, padding=3)
        self.conv3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(256, out_channels, kernel_size=4, stride=1, padding=0)

        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=1)
        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=1)

        self.activation = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.activation(self.conv1(x))
        x = self.avgpool1(x)
        x = self.activation(self.conv2(x))
        x = self.avgpool2(x)
        x = self.activation(self.conv3(x))
        x = self.conv4(x)
        return x


class AutoEncoder(nn.Module):
    """
    ë…¼ë¦¬ì  ì´ìƒ(Logical Anomaly)ì„ íƒì§€í•˜ê¸° ìœ„í•œ ë³´ì¡° ë„¤íŠ¸ì›Œí¬
    """

    def __init__(self, out_channels=384):
        super(AutoEncoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 4, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 8, stride=1, padding=0),  # Bottleneck
        )
        self.decoder = nn.Sequential(
            # Use 6 upsample steps and 3x3 convs with padding=1 to preserve spatial size
            # Starting from a 1x1 bottleneck, 1 * 2^6 = 64 final spatial resolution
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(64, 64, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(64, 64, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(64, 64, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(64, 64, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(64, 32, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False),
            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),
            # Output ì±„ë„ì„ PDNì˜ ì¶œë ¥ ì±„ë„ê³¼ ë§ì¶°ì„œ Studentê°€ í•™ìŠµí•˜ê¸° ì‰½ê²Œ í•¨
        )

    def forward(self, x):
        enc = self.encoder(x)
        dec = self.decoder(enc)
        return dec


class TimmTeacher(nn.Module):
    """
    ImageNetìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ê°•ë ¥í•œ ì„ ìƒë‹˜ (WideResNet-50)
    íŠ¹ì§• ì¶”ì¶œ(Feature Extraction)ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self, model_name="wide_resnet50_2"):
        super(TimmTeacher, self).__init__()
        # features_only=True: ë¶„ë¥˜ê¸°(Classifier)ë¥¼ ë–¼ê³  íŠ¹ì§•ë§Œ ë½‘ìŒ
        # out_indices=[1]: 2ë²ˆì§¸ ìŠ¤í…Œì´ì§€ì˜ íŠ¹ì§•ë§Œ ì‚¬ìš© (ë„ˆë¬´ ì–•ì§€ë„, ê¹Šì§€ë„ ì•Šì€ ì ì ˆí•œ ìœ„ì¹˜)
        self.model = timm.create_model(
            model_name, pretrained=True, features_only=True, out_indices=[1]
        )

        # íŒŒë¼ë¯¸í„° ê³ ì • (í•™ìŠµë˜ì§€ ì•Šë„ë¡ Freeze)
        for param in self.model.parameters():
            param.requires_grad = False

        self.model.eval()  # ì–¸ì œë‚˜ í‰ê°€ ëª¨ë“œ

    def forward(self, x):
        # timmì˜ features_only ëª¨ë¸ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•¨ [feature1, feature2, ...]
        features = self.model(x)
        return features[0]  # ìš°ë¦¬ê°€ ì„ íƒí•œ ìŠ¤í…Œì´ì§€ì˜ íŠ¹ì§• ë§µ ë°˜í™˜


# ==========================================
# 2. EfficientAD ì „ì²´ ëª¨ë¸ í´ë˜ìŠ¤
# ==========================================
class EfficientAD:
    def __init__(self, seed=42, out_channels=384, image_size=256):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.image_size = image_size

        # ì‹œë“œ ê³ ì •
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)

        # 1. Teacher (ê³ ì •ëœ ë„¤íŠ¸ì›Œí¬)
        # ---------------------------------------------------------
        # [ë³€ê²½ 1] Teacherë¥¼ Random PDN -> Pretrained WideResNetìœ¼ë¡œ êµì²´
        # ---------------------------------------------------------
        self.teacher = TimmTeacher(model_name="resnet18").to(self.device)
        self.teacher.eval()

        with torch.no_grad():
            dummy_input = torch.randn(1, 3, image_size, image_size).to(self.device)
            teacher_out = self.teacher(dummy_input)
            out_channels = teacher_out.shape[1]  # ì˜ˆ: 512
            logger.info(f"ğŸ§  Teacher Model Loaded (Channels: {out_channels})")

        # Teacher ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (ImageNet Distillation í‰ë‚´ - ëœë¤ì´ì§€ë§Œ êµ¬ì¡°ì  íŠ¹ì„± í™œìš©)
        # ì‹¤ì œ ë…¼ë¬¸ì—ì„œëŠ” ImageNet pre-trained weightsë¥¼ distillationí•˜ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” ëœë¤ ì´ˆê¸°í™”ëœ Teacherë¥¼ Ground Truthë¡œ ì‚¼ëŠ” ë³€í˜•(RD4AD ë°©ì‹)ì„ ì°¨ìš©í•´ ì˜ì¡´ì„± ì œê±°

        # ---------------------------------------------------------
        # [ë³€ê²½ 2] Studentì™€ AEì˜ ì±„ë„ ìˆ˜ë¥¼ Teacherì— ë§ì¶¤
        # ---------------------------------------------------------
        # Student(PDN)ëŠ” ê°€ë³ê²Œ ìœ ì§€í•˜ë˜, ì¶œë ¥ì¸µ(conv4)ë§Œ Teacherì™€ í¬ê¸°ë¥¼ ë§ì¶¥ë‹ˆë‹¤.
        self.student = PDN(out_channels=out_channels).to(self.device)
        self.ae = AutoEncoder(out_channels=out_channels).to(self.device)

        # ìµœì í™”ê¸° ì„¤ì • (TeacherëŠ” í•™ìŠµ ì•ˆ í•˜ë¯€ë¡œ ì œì™¸)
        self.optimizer = torch.optim.Adam(
            list(self.student.parameters()) + list(self.ae.parameters()),
            lr=1e-4,
            weight_decay=1e-5,
        )

        # ì •ê·œí™” í†µê³„ ì €ì¥ì†Œ (í¬ê¸° ë§ì¶¤)
        self.teacher_mean = torch.zeros(1, out_channels, 1, 1).to(self.device)
        self.teacher_std = torch.ones(1, out_channels, 1, 1).to(self.device)

    def _normalize_teacher_output(self, teacher_out):
        # [ìˆ˜ì •] epsilon ì¶”ê°€ë¡œ 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        return (teacher_out - self.teacher_mean) / (self.teacher_std + 1e-6)

    def calculated_hard_loss(self, teacher_out, student_out, q=0.999):
        """
        ëª¨ë“  í”½ì…€ì˜ í‰ê· ì„ êµ¬í•˜ëŠ” ëŒ€ì‹ , ì˜¤ì°¨ê°€ ê°€ì¥ í° ìƒìœ„ (1-q)% í”½ì…€ë“¤ì˜ í‰ê· ë§Œ êµ¬í•¨.
        ì‘ì€ ê²°í•¨ì„ ë†“ì¹˜ì§€ ì•Šê²Œ í•´ì¤Œ.
        """
        # (Batch, Channel, H, W) -> (Batch, -1)
        diff = (teacher_out - student_out) ** 2
        batch_size = diff.shape[0]
        flatten_diff = diff.view(batch_size, -1)

        # ìƒìœ„ kê°œ í”½ì…€ ì„ íƒ (Hard Negative Mining)
        # q=0.999ë¼ë©´ ìƒìœ„ 0.1%ì˜ ì˜¤ì°¨ë§Œ í•™ìŠµì— ë°˜ì˜
        num_hard_pixels = int(flatten_diff.shape[1] * (1 - q))
        if num_hard_pixels < 1:
            num_hard_pixels = 1

        hard_diff, _ = torch.topk(flatten_diff, k=num_hard_pixels, dim=1)
        return torch.mean(hard_diff)

    def train(self, dataloader, epochs=100):
        logger.info(f"ğŸš€ EfficientAD í•™ìŠµ ì‹œì‘ (Improved Version)")

        # 1. Teacher í†µê³„ ê³„ì‚° (ê¸°ì¡´ê³¼ ë™ì¼)
        logger.info("ğŸ“Š Teacher Output í†µê³„ ê³„ì‚° ì¤‘...")
        with torch.no_grad():
            outputs = []
            for imgs in dataloader:
                imgs = imgs.to(self.device)
                outputs.append(self.teacher(imgs))
            outputs = torch.cat(outputs, dim=0)
            self.teacher_mean = torch.mean(outputs, dim=[0, 2, 3], keepdim=True)
            self.teacher_std = torch.std(outputs, dim=[0, 2, 3], keepdim=True)
            logger.info("âœ… í†µê³„ ê³„ì‚° ì™„ë£Œ.")

        self.student.train()
        self.ae.train()

        # [ê°œì„ ] ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ (í•™ìŠµ í›„ë°˜ë¶€ ë¯¸ì„¸ ì¡°ì •)
        scheduler = torch.optim.lr_scheduler.StepLR(
            self.optimizer, step_size=int(epochs * 0.8), gamma=0.1
        )

        for epoch in range(epochs):
            total_loss = 0
            for imgs in dataloader:
                imgs = imgs.to(self.device)

                with torch.no_grad():
                    teacher_out = self.teacher(imgs)
                    teacher_out = self._normalize_teacher_output(teacher_out)

                student_out = self.student(imgs)
                ae_out = self.ae(imgs)

                # Ensure AE output spatial size matches teacher/student (avoid broadcasting warnings)
                if ae_out.shape[2:] != teacher_out.shape[2:]:
                    ae_out = F.interpolate(
                        ae_out, size=teacher_out.shape[2:], mode="bilinear", align_corners=False
                    )

                # --- [í•µì‹¬ ë³€ê²½] Loss Calculation ---

                # 1. Local Loss: Hard Feature Mining ì ìš© (q=0.99 ~ 0.999 ê¶Œì¥)
                # ì „ì²´ í‰ê·  ëŒ€ì‹  ì˜¤ì°¨ê°€ í° í”½ì…€ì— ì§‘ì¤‘í•˜ì—¬ 'ë¯¸ì„¸ ê²°í•¨' ê²€ì¶œë ¥ ìƒìŠ¹
                loss_st = self.calculated_hard_loss(teacher_out, student_out, q=0.99)

                # 2. AE Loss: ì „ì²´ì ì¸ êµ¬ì¡° í•™ìŠµì€ ê·¸ëŒ€ë¡œ MSE ì‚¬ìš© (ì „ì²´ í˜•ìƒì„ ë´ì•¼ í•˜ë¯€ë¡œ)
                loss_ae = F.mse_loss(ae_out, teacher_out)

                # 3. ST-AE Loss: Studentê°€ AEë¥¼ ë”°ë¼í•˜ê²Œ í•¨
                loss_st_ae = F.mse_loss(student_out, ae_out.detach())

                # ê°€ì¤‘ì¹˜ ì¡°ì ˆ (ë…¼ë¬¸ì—ì„œëŠ” loss_stì— ê°€ì¤‘ì¹˜ë¥¼ 1ë¡œ ë‘ì§€ë§Œ,
                # ë¯¸ì„¸ ê²°í•¨ì´ ì¤‘ìš”í•˜ë‹¤ë©´ loss_st ë¹„ì¤‘ì„ ë†’ì„)
                loss = loss_st + loss_ae + loss_st_ae

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

                total_loss += loss.item()

            scheduler.step()  # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸

            if (epoch + 1) % 10 == 0:
                logger.info(
                    f"Epoch {epoch+1}/{epochs} | Loss: {total_loss / len(dataloader):.6f}"
                )

        logger.info("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")

    def predict(self, img):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
        img: Tensor (1, 3, H, W)
        Return: Anomaly Map (H, W), Score (float)
        """
        self.student.eval()
        self.ae.eval()

        img = img.to(self.device)

        with torch.no_grad():
            teacher_out = self.teacher(img)
            teacher_out = self._normalize_teacher_output(teacher_out)

            student_out = self.student(img)
            ae_out = self.ae(img)
            # Upsample AE output to teacher spatial size if needed
            if ae_out.shape[2:] != teacher_out.shape[2:]:
                ae_out = F.interpolate(
                    ae_out, size=teacher_out.shape[2:], mode="bilinear", align_corners=False
                )
            # 1. Local Map: Teacher vs Student ì°¨ì´
            # ì±„ë„ ë°©í–¥ìœ¼ë¡œ í‰ê· ì„ ë‚´ì–´ (H, W) ë§µ ìƒì„±
            map_st = torch.mean((teacher_out - student_out) ** 2, dim=1, keepdim=True)

            # 2. Global Map: Teacher vs AE ì°¨ì´
            map_ae = torch.mean((teacher_out - ae_out) ** 2, dim=1, keepdim=True)

            # 3. ê²°í•©
            combined_map = map_st + map_ae

            # ì›ë³¸ í•´ìƒë„ë¡œ Upsample
            anomaly_map = F.interpolate(
                combined_map,
                size=(self.image_size, self.image_size),
                mode="bilinear",
                align_corners=False,
            )

            # ê²°ê³¼ ê°€ê³µ
            anomaly_map = anomaly_map[0, 0].cpu().numpy()
            anomaly_score = np.max(anomaly_map)  # ê°€ì¥ ì´ìƒí•œ ë¶€ë¶„ì˜ ì ìˆ˜

        return anomaly_map, anomaly_score


# ==========================================
# 3. ì‹¤í–‰ ìœ í‹¸ë¦¬í‹°
# ==========================================
def get_dataloader(data_dir, img_size=256, batch_size=16):
    transform = build_torch_transform(resize_size=img_size, crop_size=None, normalize=True)
    return make_torch_dataloader(
        data_dir,
        batch_size=batch_size,
        num_workers=4,
        transform=transform,
        shuffle=True,
        recursive=True,
    )


# ==========================================
# ì‚¬ìš© ì˜ˆì‹œ
# ==========================================
if __name__ == "__main__":
    # 1. ë°ì´í„° ê²½ë¡œ ì„¤ì •
    DATA_PATH = "data/mvtec/bottle/train/good"  # ì˜ˆì‹œ ê²½ë¡œ

    if os.path.exists(DATA_PATH):
        # 2. ë°ì´í„° ë¡œë” ì¤€ë¹„
        loader = get_dataloader(DATA_PATH, img_size=256, batch_size=8)

        # 3. ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
        model = EfficientAD(out_channels=384, image_size=256)
        model.train(loader, epochs=50)  # EfficientADëŠ” ë¹¨ë¦¬ ìˆ˜ë ´í•˜ë¯€ë¡œ Epoch ì ì–´ë„ ë¨

        # 4. ì¶”ë¡  í…ŒìŠ¤íŠ¸
        test_img, _ = next(iter(loader))  # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ í•˜ë‚˜ êº¼ëƒ„
        test_img = test_img[0:1]  # (1, 3, 256, 256)

        a_map, a_score = model.predict(test_img)
        print(f"Detected Anomaly Score: {a_score:.4f}")

        # ì‹œê°í™” (Matplotlib)
        import matplotlib.pyplot as plt

        plt.imshow(a_map, cmap="jet")
        plt.title(f"Anomaly Map (Score: {a_score:.2f})")
        plt.colorbar()
        plt.show()
    else:
        print(f"ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {DATA_PATH}")
        print("MVTec ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì…ë ¥í•˜ë©´ ë°”ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")

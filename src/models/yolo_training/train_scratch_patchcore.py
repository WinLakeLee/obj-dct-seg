"""
PatchCoreë¥¼ ì‚¬ìš©í•œ ìŠ¤í¬ë˜ì¹˜ Anomaly Detection í•™ìŠµ

ë°ì´í„°ì…‹: yolo_training/prepare_scratch_anomaly_dataset.pyë¡œ ìƒì„±ëœ MVTec í˜•ì‹ ë°ì´í„°
ëª¨ë¸: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ PatchCore (Wide ResNet-50)

ì‚¬ìš©ë²•:
    python yolo_training/train_scratch_patchcore.py
"""

import sys
from pathlib import Path
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
import numpy as np
import time

# PatchCore ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from PatchCore.patch_core import PatchCoreOptimized

def get_transforms(resize_size=256, crop_size=224):
    """ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸"""
    return transforms.Compose([
        transforms.Resize(resize_size),
        transforms.CenterCrop(crop_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

def make_dataloader(data_dir, batch_size=8, shuffle=True):
    """ë‹¨ì¼ í´ë”ì˜ ì´ë¯¸ì§€ ë°ì´í„°ë¡œë” ìƒì„± (ë¼ë²¨ ì—†ìŒ)"""
    from PIL import Image
    
    transform = get_transforms()
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
    image_files = list(Path(data_dir).glob('*.jpg')) + list(Path(data_dir).glob('*.png'))
    
    class SimpleImageDataset(torch.utils.data.Dataset):
        def __init__(self, image_paths, transform=None):
            self.image_paths = image_paths
            self.transform = transform
        
        def __len__(self):
            return len(self.image_paths)
        
        def __getitem__(self, idx):
            img_path = self.image_paths[idx]
            img = Image.open(img_path).convert('RGB')
            if self.transform:
                img = self.transform(img)
            return img, 0  # ë”ë¯¸ ë¼ë²¨ (í‰ê°€ìš©)
    
    dataset = SimpleImageDataset(image_files, transform=transform)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)
    return loader

def tensor_only(loader):
    """DataLoaderì—ì„œ ì´ë¯¸ì§€ë§Œ ì¶”ì¶œ (ë¼ë²¨ ì œê±°)"""
    for batch in loader:
        if isinstance(batch, (list, tuple)) and len(batch) >= 1:
            imgs = batch[0]
        else:
            imgs = batch
        yield imgs

def evaluate_model(model, test_good_loader, test_scratch_loader, device):
    """ëª¨ë¸ í‰ê°€"""
    print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘...")
    
    # ì •ìƒ ìƒ˜í”Œ í‰ê°€
    good_scores = []
    for imgs, _ in test_good_loader:
        imgs = imgs.to(device)
        scores = model.predict(imgs, score_type="max")
        good_scores.extend(scores)
    
    # ìŠ¤í¬ë˜ì¹˜ ìƒ˜í”Œ í‰ê°€
    scratch_scores = []
    for imgs, _ in test_scratch_loader:
        imgs = imgs.to(device)
        scores = model.predict(imgs, score_type="max")
        scratch_scores.extend(scores)
    
    # í†µê³„ ê³„ì‚°
    good_mean = np.mean(good_scores) if good_scores else 0
    good_std = np.std(good_scores) if good_scores else 0
    scratch_mean = np.mean(scratch_scores) if scratch_scores else 0
    scratch_std = np.std(scratch_scores) if scratch_scores else 0
    
    # ì„ê³„ê°’ ê³„ì‚° (ì •ìƒ ìƒ˜í”Œ í‰ê·  + 2*std)
    threshold = good_mean + 2 * good_std
    
    # ì •í™•ë„ ê³„ì‚°
    good_correct = sum(1 for s in good_scores if s < threshold)
    scratch_correct = sum(1 for s in scratch_scores if s >= threshold)
    
    total_correct = good_correct + scratch_correct
    total_samples = len(good_scores) + len(scratch_scores)
    accuracy = total_correct / total_samples if total_samples > 0 else 0
    
    return {
        'good_mean': good_mean,
        'good_std': good_std,
        'scratch_mean': scratch_mean,
        'scratch_std': scratch_std,
        'threshold': threshold,
        'accuracy': accuracy,
        'good_accuracy': good_correct / len(good_scores) if good_scores else 0,
        'scratch_accuracy': scratch_correct / len(scratch_scores) if scratch_scores else 0,
    }

def train_scratch_patchcore():
    """ìŠ¤í¬ë˜ì¹˜ ê°ì§€ìš© PatchCore í•™ìŠµ"""
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ
    data_root = Path('data/scratch_anomaly')
    train_dir = data_root / 'train' / 'good'
    test_good_dir = data_root / 'test' / 'good'
    test_scratch_dir = data_root / 'test' / 'scratch'
    
    if not train_dir.exists():
        print(f"âŒ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤: {train_dir}")
        print(f"   ë¨¼ì € prepare_scratch_anomaly_dataset.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # GPU ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  Device: {device}")
    
    # 1. ë°ì´í„° ë¡œë” ìƒì„±
    print(f"\nğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”©...")
    print(f"   Train: {train_dir}")
    print(f"   Test Good: {test_good_dir}")
    print(f"   Test Scratch: {test_scratch_dir}")
    
    train_loader = make_dataloader(train_dir, batch_size=8)
    
    # 2. PatchCore ëª¨ë¸ ìƒì„±
    print(f"\nğŸ§  PatchCore ëª¨ë¸ ìƒì„±")
    model = PatchCoreOptimized(
        backbone_name="wide_resnet50_2",   # WideResNet-50 backbone
        sampling_ratio=0.01,               # Coreset sampling 1%
        use_fp16=True,                     # FP16 ìµœì í™”
    ).to(device)
    
    # 3. í•™ìŠµ ì‹œì‘
    print(f"\nğŸš€ PatchCore í•™ìŠµ ì‹œì‘...")
    print(f"   - ì •ìƒ ìƒ˜í”Œë¡œ feature memory bank êµ¬ì¶•")
    print(f"   - Coreset Samplingìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”")
    print(f"   - FP16 ëª¨ë“œë¡œ ì†ë„ ìµœì í™”")
    
    start_time = time.time()
    
    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
    checkpoint_dir = Path('models/patchcore_scratch')
    
    model.fit(
        tensor_only(train_loader),
        n_neighbors=9,
        checkpoint_dir=str(checkpoint_dir),
        checkpoint_interval=10
    )
    
    elapsed = time.time() - start_time
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ)")
    
    # 4. ëª¨ë¸ ì €ì¥
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {checkpoint_dir}")
    print(f"   - memory_bank.npy: Feature memory bank")
    print(f"   - meta.json: ëª¨ë¸ ë©”íƒ€ë°ì´í„°")
    
    # 5. í…ŒìŠ¤íŠ¸ í‰ê°€
    if test_good_dir.exists() and test_scratch_dir.exists():
        test_good_loader = make_dataloader(test_good_dir, batch_size=4, shuffle=False)
        test_scratch_loader = make_dataloader(test_scratch_dir, batch_size=4, shuffle=False)
        
        results = evaluate_model(model, test_good_loader, test_scratch_loader, device)
        
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ì •ìƒ ìƒ˜í”Œ í‰ê·  ì ìˆ˜: {results['good_mean']:.4f} Â± {results['good_std']:.4f}")
        print(f"   ìŠ¤í¬ë˜ì¹˜ ìƒ˜í”Œ í‰ê·  ì ìˆ˜: {results['scratch_mean']:.4f} Â± {results['scratch_std']:.4f}")
        print(f"   ì„ê³„ê°’: {results['threshold']:.4f}")
        print(f"   ì „ì²´ ì •í™•ë„: {results['accuracy']:.2%}")
        print(f"   ì •ìƒ ìƒ˜í”Œ ì •í™•ë„: {results['good_accuracy']:.2%}")
        print(f"   ìŠ¤í¬ë˜ì¹˜ ìƒ˜í”Œ ì •í™•ë„: {results['scratch_accuracy']:.2%}")
        
        if results['scratch_mean'] > results['good_mean']:
            print(f"\nâœ… ìŠ¤í¬ë˜ì¹˜ ê°ì§€ ì„±ê³µ! (ìŠ¤í¬ë˜ì¹˜ ì ìˆ˜ > ì •ìƒ ì ìˆ˜)")
        else:
            print(f"\nâš ï¸  ê²½ê³ : ìŠ¤í¬ë˜ì¹˜ ì ìˆ˜ê°€ ì •ìƒ ì ìˆ˜ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.")
            print(f"      ë” ë§ì€ í•™ìŠµ ë°ì´í„° ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    train_scratch_patchcore()
